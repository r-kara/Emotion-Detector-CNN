Index: Part_3/cnn_kfold.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision.transforms import transforms\r\nfrom torchvision.datasets import ImageFolder\r\nimport torch.nn.functional as F\r\nfrom sklearn.model_selection import KFold\r\nfrom sklearn.metrics import precision_recall_fscore_support\r\nfrom sklearn.metrics import accuracy_score\r\n\r\n# Set random seed for reproducibility\r\ntorch.manual_seed(42)\r\n\r\ntransform = transforms.Compose([\r\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\r\n    transforms.ToTensor(),  # Convert PIL Image to Tensor\r\n])\r\n\r\n# some variables:\r\nbatch_size = 64\r\nlr = 0.001\r\n\r\n\r\n# Define dataset and dataloaders\r\n# train_dataset = ImageFolder(root='../Part_2/NewDataset/training', transform=transform)\r\n# val_dataset = ImageFolder(root='../Part_2/NewDataset/validation', transform=transform)\r\n# test_dataset = ImageFolder(root='../Part_2/NewDataset/testing', transform=transform)\r\n#\r\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n# val_loader = DataLoader(val_dataset, batch_size=batch_size)\r\n# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\r\n\r\nclass MainCNN(nn.Module):\r\n    def __init__(self):\r\n        super(MainCNN, self).__init__()\r\n\r\n        # Convolution Layer 1, our input images are: 48 x 48 x 1 -> 1 for grayscale\r\n        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)  # 1 for grayscale, 20 for number of kernels -> 44 x 44 x 20\r\n        self.relu1 = nn.ReLU()  # activation function, 44 x 44 x 20\r\n\r\n        # Convolution Layer 2\r\n        self.conv2 = nn.Conv2d(20, 25, kernel_size=5)  # dimensions 20 x 20 x 25\r\n        self.conv2_drop = nn.Dropout2d(p=0.5)\r\n        self.maxpool2 = nn.MaxPool2d(2)  # the dimensions will drop by 2: 10 x 10 x 25\r\n        self.relu2 = nn.ReLU()\r\n\r\n        # Fully connected layers\r\n        self.fc1 = nn.Linear(46 * 46 * 25, 450)\r\n        self.fc2 = nn.Linear(450, 4)  # out is 4 classes\r\n\r\n    def forward(self, x):\r\n        # Convolution layer 1:\r\n        x = self.conv1(x)\r\n        x = self.relu1(x)\r\n\r\n        # Convolution layer 2:\r\n        x = self.conv2(x)\r\n        x = self.conv2_drop(x)\r\n        x = self.maxpool2(x)\r\n        x = self.relu2(x)\r\n\r\n        # switch from activation map to vectors\r\n        x = x.view(-1, 46 * 46 * 25)\r\n\r\n        # Fully connected layers\r\n        x = self.fc1(x)\r\n        x = F.relu(x)\r\n        x = F.dropout(x, training=True)\r\n        x = self.fc2(x)\r\n\r\n        return x\r\n\r\n\r\ndef train_model_kfold(model, datas, num_epochs=10, lr=0.001, patience=5, numKfold=10):\r\n    criterion = nn.CrossEntropyLoss()\r\n    optimizer = optim.Adam(model.parameters(), lr=lr)\r\n    best_val_loss = float('inf')\r\n    early_stopping_counter = 0\r\n    # Here, evaluation metrics\r\n    accuracy_fold = []\r\n    precision_micro_fold = []\r\n    recall_micro_fold = []\r\n    f1_micro_fold = []\r\n\r\n    precision_macro_fold = []\r\n    recall_macro_fold = []\r\n    f1_macro_fold = []\r\n\r\n    kf = KFold(n_splits=numKfold, shuffle=True, random_state=0)\r\n\r\n    fold_nb = 1\r\n    # Feed the split function the dataset path\r\n    # for each fold, starting with fold nb1:\r\n    for train, test in kf.split(datas):\r\n        print(\"----------------------------------------------------------------\")\r\n        train_data = torch.utils.data.Subset(datas, train)\r\n        test_data = torch.utils.data.Subset(datas, test)\r\n        # Data Loaders:\r\n        train_load = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n        test_load = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\r\n\r\n        print(f\"Fold: {fold_nb}/{numKfold}\")\r\n        # Training loop\r\n        for epoch in range(num_epochs):\r\n            # Training\r\n            model.train()\r\n            train_loss = 0.0\r\n            for images, labels in train_load:\r\n                optimizer.zero_grad()\r\n                outputs = model(images)\r\n                loss = criterion(outputs, labels)\r\n                loss.backward()\r\n                optimizer.step()\r\n                train_loss += loss.item() * images.size(0)\r\n            train_loss /= len(train_load.dataset)\r\n\r\n            # Validation\r\n            model.eval()\r\n            val_loss = 0.0\r\n            for images, labels in test_load:\r\n                outputs = model(images)\r\n                loss = criterion(outputs, labels)\r\n                val_loss += loss.item() * images.size(0)\r\n            val_loss /= len(test_load.dataset)\r\n\r\n            # Print training and validation loss\r\n            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\r\n\r\n            # Early stopping\r\n            if val_loss < best_val_loss:\r\n                best_val_loss = val_loss\r\n                early_stopping_counter = 0\r\n                # Save the best model\r\n                # torch.save(model.state_dict(), 'Models/best_model_maincnn.pth')\r\n            else:\r\n                early_stopping_counter += 1\r\n                if early_stopping_counter >= patience:\r\n                    print(\"Early stopping triggered!\")\r\n                    break\r\n\r\n        print(f\"Fold {fold_nb}: Training completed.\")\r\n        # Save the trained model\r\n        # torch.save(model.state_dict(), 'Models/final_model_maincnn.pth')\r\n\r\n        # Evaluating the fold\r\n        model.eval()\r\n        predictions = []\r\n        actual = []\r\n        with torch.no_grad():\r\n            for images, labels in test_load:\r\n                outputs = model(images)\r\n                _, predicted = torch.max(outputs, 1)\r\n                predictions.extend(predicted.cpu().numpy())\r\n                actual.extend(labels.cpu().numpy())\r\n\r\n        # Next, calculate the evaluation metrics needed for this fold:\r\n        accuracy_fold.append(accuracy_score(actual, predictions))\r\n        # Micro metrics\r\n        precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(actual, predictions,\r\n                                                                                     average='micro')\r\n        precision_micro_fold.append(precision_micro)\r\n        recall_micro_fold.append(recall_micro_fold)\r\n        f1_micro_fold.append(f1_micro)\r\n\r\n        # Macro metrics\r\n        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(actual, predictions,\r\n                                                                                     average='macro')\r\n        precision_macro_fold.append(precision_macro)\r\n        recall_macro_fold.append(recall_macro)\r\n        f1_macro_fold.append(f1_macro)\r\n\r\n        # Printing the metrics for each fold one at a time\r\n        print(f\" Fold {fold_nb}/{numKfold}:\")\r\n        print(f\" Accuracy: {accuracy_fold[-1]:.4f}\")\r\n        print(\"Micro values: \")\r\n        print(\r\n            f\" Micro Precision: {precision_micro:.4f}, Micro Recall: {recall_micro:.4f}, Micro F1-score: {f1_micro:.4f}\")\r\n        print(\"Macro values: \")\r\n        print(\r\n            f\" Macro Precision: {precision_macro:.4f}, Micro Recall: {recall_macro:.4f}, Micro F1-score: {f1_macro:.4f}\")\r\n        # Updating the fold number\r\n        fold_nb += 1\r\n    # Calculating average of metrics of all folds\r\n    avg_accuracy = sum(accuracy_fold) / len(accuracy_fold)\r\n    avg_precision_micro = sum(precision_micro_fold) / len(precision_micro_fold)\r\n    avg_recall_micro = sum(recall_micro_fold) / len(recall_micro_fold)\r\n    avg_f1_micro = sum(f1_micro_fold) / len(f1_micro_fold)\r\n\r\n    avg_precision_macro = sum(precision_macro_fold) / len(precision_macro_fold)\r\n    avg_recall_macro = sum(recall_macro_fold) / len(recall_macro_fold)\r\n    avg_f1_macro = sum(f1_macro_fold) / len(f1_macro_fold)\r\n\r\n    print(\"Average values:\")\r\n    print(f\" Average Accuracy: {avg_accuracy:.4f}\")\r\n    print(\"Micro values: \")\r\n    print(f\" Average Precision: {avg_precision_micro}, Average Recall: {avg_recall_micro}, Average F1: {avg_f1_micro}\")\r\n    print(\"Macro values: \")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    # Set random seed for reproducibility\r\n    torch.manual_seed(42)\r\n\r\n    transform = transforms.Compose([\r\n        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\r\n        transforms.ToTensor(),  # Convert PIL Image to Tensor\r\n    ])\r\n\r\n    batch_size = 64\r\n    lr = 0.001\r\n    kfolds = 10\r\n\r\n    # Define dataset and dataloaders\r\n    # train_dataset = ImageFolder(root='../Part_2/NewDataset/training', transform=transform)\r\n    # val_dataset = ImageFolder(root='../Part_2/NewDataset/validation', transform=transform)\r\n    # test_dataset = ImageFolder(root='../Part_2/NewDataset/testing', transform=transform)\r\n\r\n    # Getting the dataset\r\n    data = ImageFolder(root='../Part_3/Dataset', transform=transform)\r\n    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n    # val_loader = DataLoader(val_dataset, batch_size=batch_size)\r\n    # test_loader = DataLoader(test_dataset, batch_size=batch_size)\r\n\r\n    # Initialize the model\r\n    model = MainCNN()\r\n\r\n    # Train the model\r\n    train_model_kfold(model, data, kfolds)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Part_3/cnn_kfold.py b/Part_3/cnn_kfold.py
--- a/Part_3/cnn_kfold.py	
+++ b/Part_3/cnn_kfold.py	
@@ -185,6 +185,7 @@
     avg_accuracy = sum(accuracy_fold) / len(accuracy_fold)
     avg_precision_micro = sum(precision_micro_fold) / len(precision_micro_fold)
     avg_recall_micro = sum(recall_micro_fold) / len(recall_micro_fold)
+
     avg_f1_micro = sum(f1_micro_fold) / len(f1_micro_fold)
 
     avg_precision_macro = sum(precision_macro_fold) / len(precision_macro_fold)
@@ -196,6 +197,7 @@
     print("Micro values: ")
     print(f" Average Precision: {avg_precision_micro}, Average Recall: {avg_recall_micro}, Average F1: {avg_f1_micro}")
     print("Macro values: ")
+    print(f" Average Precision: {avg_precision_macro}, Average Recall: {avg_recall_macro}, Average F1: {avg_f1_macro}")
 
 
 if __name__ == "__main__":
